{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "16x3USLOx0mc2fJo9Tee3baauBSLzV1Hv",
      "authorship_tag": "ABX9TyPWbdLUSBp/7HMK9Xou9c+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jananibabu17112004-ctrl/variant-pathogenicity-streamlit17/blob/main/geneprj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAGvtgP_nB6P",
        "outputId": "635ad8f2-486d-463e-d9cd-61fa5fc53d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THYYevRuEBZx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# ----------------------------------\n",
        "# PAGE CONFIG\n",
        "# ----------------------------------\n",
        "st.set_page_config(page_title=\"Variant Classification Demo\", layout=\"centered\")\n",
        "st.title(\"üß¨ Genetic Variant Classification\")\n",
        "st.write(\"Transformer vs BiLSTM ‚Äì Deep Learning Comparison\")\n",
        "\n",
        "BASE_PATH = \".\"\n",
        "\n",
        "# ----------------------------------\n",
        "# LOAD ENCODERS\n",
        "# ----------------------------------\n",
        "@st.cache_resource\n",
        "def load_encoders():\n",
        "    with open(f\"{BASE_PATH}/encoders.pkl\", \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "encoders = load_encoders()\n",
        "\n",
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n",
        "\n",
        "# ----------------------------------\n",
        "# SAFE ENCODING FUNCTION\n",
        "# ----------------------------------\n",
        "def safe_encode(le, value):\n",
        "    if value in le.classes_:\n",
        "        return le.transform([value])[0]\n",
        "    return 0\n",
        "\n",
        "# ----------------------------------\n",
        "# BUILD DEMO MODELS (LIGHTWEIGHT)\n",
        "# ----------------------------------\n",
        "@st.cache_resource\n",
        "def build_transformer():\n",
        "    inp = tf.keras.Input(shape=(4,))\n",
        "    x = tf.keras.layers.Embedding(100000, 64)(inp)\n",
        "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    out = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "    model = tf.keras.Model(inp, out)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\")\n",
        "    return model\n",
        "\n",
        "@st.cache_resource\n",
        "def build_bilstm():\n",
        "    inp = tf.keras.Input(shape=(4,))\n",
        "    x = tf.keras.layers.Embedding(100000, 64)(inp)\n",
        "    x = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(64)\n",
        "    )(x)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    out = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "    model = tf.keras.Model(inp, out)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\")\n",
        "    return model\n",
        "\n",
        "transformer_model = build_transformer()\n",
        "bilstm_model = build_bilstm()\n",
        "\n",
        "# ----------------------------------\n",
        "# USER INPUTS\n",
        "# ----------------------------------\n",
        "model_choice = st.selectbox(\n",
        "    \"Select Model\",\n",
        "    [\"Transformer (Base Model)\", \"BiLSTM (Comparison Model)\"]\n",
        ")\n",
        "\n",
        "gene = st.selectbox(\"Gene Symbol\", sorted(gene_le.classes_))\n",
        "variant_type = st.selectbox(\"Variant Type\", sorted(type_le.classes_))\n",
        "review_status = st.selectbox(\"Review Status\", sorted(review_le.classes_))\n",
        "assembly = st.selectbox(\"Genome Assembly\", sorted(assembly_le.classes_))\n",
        "\n",
        "# ----------------------------------\n",
        "# PREDICTION\n",
        "# ----------------------------------\n",
        "if st.button(\"üîç Predict\"):\n",
        "    input_seq = np.array([[\n",
        "        safe_encode(gene_le, gene),\n",
        "        safe_encode(type_le, variant_type),\n",
        "        safe_encode(review_le, review_status),\n",
        "        safe_encode(assembly_le, assembly)\n",
        "    ]])\n",
        "\n",
        "    if model_choice.startswith(\"Transformer\"):\n",
        "        probs = transformer_model.predict(input_seq, verbose=0)[0]\n",
        "    else:\n",
        "        probs = bilstm_model.predict(input_seq, verbose=0)[0]\n",
        "\n",
        "    labels = [\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "    predicted_label = labels[int(np.argmax(probs))]\n",
        "    confidence = float(np.max(probs))\n",
        "\n",
        "    st.success(f\"Prediction: **{predicted_label}**\")\n",
        "    st.info(f\"Confidence: **{confidence:.2f}**\")\n",
        "\n",
        "    # ----------------------------------\n",
        "    # PROBABILITY BAR CHART\n",
        "    # ----------------------------------\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(labels, probs)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_ylabel(\"Probability\")\n",
        "    ax.set_title(\"Prediction Probabilities\")\n",
        "\n",
        "    for i, v in enumerate(probs):\n",
        "        ax.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n",
        "\n",
        "    st.pyplot(fig)\n"
      ],
      "metadata": {
        "id": "kDjk7ry5FfQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "tN5DUFieF0eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Runtime ‚Üí Restart runtime\n"
      ],
      "metadata": {
        "id": "FLT_kp5uF7tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "print(\"Streamlit installed!\")\n"
      ],
      "metadata": {
        "id": "iwhPdoWoGAWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_predict(gene, variant_type, review_status, assembly):\n",
        "    input_seq = np.array([[\n",
        "        safe_encode(gene_le, gene),\n",
        "        safe_encode(type_le, variant_type),\n",
        "        safe_encode(review_le, review_status),\n",
        "        safe_encode(assembly_le, assembly)\n",
        "    ]])\n",
        "\n",
        "    probs = model.predict(input_seq, verbose=0)[0]\n",
        "    labels = [\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "\n",
        "    for l, p in zip(labels, probs):\n",
        "        print(f\"{l}: {p:.2f}\")\n",
        "\n",
        "    print(\"\\nPrediction:\", labels[np.argmax(probs)])\n"
      ],
      "metadata": {
        "id": "XuqrfXKBMARM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_predict(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "zuhSNFqLMCsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "mrO5Y5ZXMN7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "-kseOaLRodxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_predict(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "0KGJwxjZMThY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Safe encoding function\n",
        "def safe_encode(le, value):\n",
        "    if value in le.classes_:\n",
        "        return le.transform([value])[0]\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "l2ddbiXMMcHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n"
      ],
      "metadata": {
        "id": "AiiYpV8-MgfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"encoders.pkl\", \"rb\") as f:\n",
        "    encoders = pickle.load(f)\n",
        "\n",
        "print(\"Encoders loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "0LV7zInPMpko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "9cetIlcIOG3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/UG_Project\n"
      ],
      "metadata": {
        "id": "8piH6yGGONBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "ENCODER_PATH = \"/content/drive/MyDrive/UG_Project/encoders.pkl\"\n",
        "\n",
        "with open(ENCODER_PATH, \"rb\") as f:\n",
        "    encoders = pickle.load(f)\n",
        "\n",
        "print(\"Encoders loaded successfully\")\n",
        "print(encoders.keys())\n"
      ],
      "metadata": {
        "id": "izmShy6VOU58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n",
        "\n",
        "print(\"All encoders ready\")\n"
      ],
      "metadata": {
        "id": "KwmIx6mGOa7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/UG_Project/transssv_style_model.keras\"\n",
        "\n",
        "model = tf.keras.models.load_model(\n",
        "    MODEL_PATH,\n",
        "    compile=False,\n",
        "    safe_mode=False\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully\")\n"
      ],
      "metadata": {
        "id": "2SC26etdOfPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Simple demo inference model\n",
        "inp = tf.keras.Input(shape=(4,))\n",
        "x = tf.keras.layers.Embedding(100000, 64)(inp)\n",
        "x = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(64)\n",
        ")(x)\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "out = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inp, out)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "print(\"Demo inference model ready\")\n"
      ],
      "metadata": {
        "id": "tmULjiGtOxki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_predict(gene, variant_type, review_status, assembly):\n",
        "    input_data = np.array([[\n",
        "        safe_encode(gene_le, gene),\n",
        "        safe_encode(type_le, variant_type),\n",
        "        safe_encode(review_le, review_status),\n",
        "        safe_encode(assembly_le, assembly)\n",
        "    ]])\n",
        "\n",
        "    probs = model.predict(input_data, verbose=0)[0]\n",
        "    labels = [\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "\n",
        "    print(\"Prediction probabilities:\")\n",
        "    for l, p in zip(labels, probs):\n",
        "        print(f\"{l}: {p:.2f}\")\n",
        "\n",
        "    print(\"\\nFinal Prediction:\", labels[np.argmax(probs)])\n"
      ],
      "metadata": {
        "id": "2RlRcd0SO1Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_predict(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "o_y5VTPNO5DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8576f366"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to the gzipped text file\n",
        "file_path = '/variant_summary.txt.gz'\n",
        "\n",
        "# Read the gzipped text file into a pandas DataFrame.\n",
        "# Assuming it's a tab-separated file. If it's comma-separated or another delimiter,\n",
        "# you might need to adjust the 'delimiter' or 'sep' parameter.\n",
        "try:\n",
        "    df = pd.read_csv(file_path, compression='gzip', sep='\\t')\n",
        "    print(f\"Successfully loaded '{file_path}' into a DataFrame.\")\n",
        "    print(\"Displaying the first 5 rows:\")\n",
        "    display(df.head())\n",
        "    print(\"\\nDataFrame Info:\")\n",
        "    df.info()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the file: {e}\")\n",
        "    print(\"Please check if the file format (e.g., delimiter) is correct, or if the file is truly a text file.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "id": "RyY2MfwgqEz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "to2_GY4gqn5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_variant(gene, variant_type, review_status, assembly):\n",
        "    # Safe encoding (prevents crashes)\n",
        "    def safe_encode(le, value):\n",
        "        if value in le.classes_:\n",
        "            return le.transform([value])[0]\n",
        "        else:\n",
        "            return 0  # fallback\n",
        "\n",
        "    gene_enc = safe_encode(gene_le, gene)\n",
        "    type_enc = safe_encode(type_le, variant_type)\n",
        "    review_enc = safe_encode(review_le, review_status)\n",
        "    assembly_enc = safe_encode(assembly_le, assembly)\n",
        "\n",
        "    input_data = {\n",
        "        \"gene_input\": np.array([gene_enc]),\n",
        "        \"type_input\": np.array([type_enc]),\n",
        "        \"review_input\": np.array([review_enc]),\n",
        "        \"assembly_input\": np.array([assembly_enc])\n",
        "    }\n",
        "\n",
        "    pred = model.predict(input_data, verbose=0)\n",
        "    pred_class = int(np.argmax(pred))\n",
        "    confidence = float(np.max(pred))\n",
        "\n",
        "    label_map = {\n",
        "        0: \"BENIGN\",\n",
        "        1: \"VUS\",\n",
        "        2: \"PATHOGENIC\"\n",
        "    }\n",
        "\n",
        "    return label_map[pred_class], round(confidence, 3)\n"
      ],
      "metadata": {
        "id": "LyJxDKZvGQ9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, conf = predict_variant(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "print(\"Prediction:\", result)\n",
        "print(\"Confidence:\", conf)\n"
      ],
      "metadata": {
        "id": "UJ9bFlMqGUPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n",
        "\n",
        "with open(f\"{BASE_PATH}/encoders.pkl\", \"rb\") as f:\n",
        "    encoders = pickle.load(f)\n",
        "\n",
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n",
        "\n",
        "print(\"Encoders loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "8YDMozuDGoOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n",
        "\n",
        "# Load cleaned dataset\n",
        "df = pd.read_csv(f\"{BASE_PATH}/variant_summary_cleaned1.csv\")\n",
        "\n",
        "encoders = {}\n",
        "\n",
        "for col in [\"GeneSymbol\", \"Type\", \"ReviewStatus\", \"Assembly\"]:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "print(\"Encoders rebuilt successfully!\")\n"
      ],
      "metadata": {
        "id": "DI3Ku1pgG8ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{BASE_PATH}/encoders.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoders, f)\n",
        "\n",
        "print(\"Encoders saved successfully!\")\n"
      ],
      "metadata": {
        "id": "uObgS4YmHIx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{BASE_PATH}/encoders.pkl\", \"rb\") as f:\n",
        "    encoders = pickle.load(f)\n",
        "\n",
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n",
        "\n",
        "print(\"Encoders loaded:\", len(gene_le.classes_))\n"
      ],
      "metadata": {
        "id": "kSWoxS9nHPmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, conf = predict_variant(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "print(result, conf)\n"
      ],
      "metadata": {
        "id": "DEiaYYKJHZpu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2575e1e9-ca76-4a8f-f855-afc5253eee68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predict_variant' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2745927339.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result, conf = predict_variant(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mgene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BRCA1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvariant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"single nucleotide variant\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreview_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"criteria provided, multiple submitters, no conflicts\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0massembly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRCh38\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_variant' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Dense, Concatenate, Dropout,\n",
        "    LayerNormalization, Flatten, MultiHeadAttention, Reshape\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Vocabulary sizes from encoders\n",
        "num_genes = len(gene_le.classes_)\n",
        "num_types = len(type_le.classes_)\n",
        "num_reviews = len(review_le.classes_)\n",
        "num_assembly = len(assembly_le.classes_)\n",
        "\n",
        "# Inputs\n",
        "gene_input = Input(shape=(1,), name=\"gene_input\")\n",
        "type_input = Input(shape=(1,), name=\"type_input\")\n",
        "review_input = Input(shape=(1,), name=\"review_input\")\n",
        "assembly_input = Input(shape=(1,), name=\"assembly_input\")\n",
        "\n",
        "# Embeddings\n",
        "gene_emb = Embedding(num_genes, 64)(gene_input)\n",
        "type_emb = Embedding(num_types, 8)(type_input)\n",
        "review_emb = Embedding(num_reviews, 16)(review_input)\n",
        "assembly_emb = Embedding(num_assembly, 4)(assembly_input)\n",
        "\n",
        "# Concatenate\n",
        "x = Concatenate()([\n",
        "    Flatten()(gene_emb),\n",
        "    Flatten()(type_emb),\n",
        "    Flatten()(review_emb),\n",
        "    Flatten()(assembly_emb)\n",
        "])\n",
        "\n",
        "# Projection\n",
        "x_proj = Dense(256, activation=\"relu\")(x)\n",
        "\n",
        "# Attention block (NO Lambda)\n",
        "x_seq = Reshape((1, 256))(x_proj)\n",
        "attn = MultiHeadAttention(num_heads=4, key_dim=64)(x_seq, x_seq)\n",
        "attn = Reshape((256,))(attn)\n",
        "\n",
        "x_attn = LayerNormalization()(x_proj + attn)\n",
        "\n",
        "# Feed-forward\n",
        "ffn = Dense(256, activation=\"relu\")(x_attn)\n",
        "x_attn = LayerNormalization()(x_attn + ffn)\n",
        "\n",
        "# Classifier\n",
        "x = Dense(128, activation=\"relu\")(x_attn)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "output = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "# Build model\n",
        "model = Model(\n",
        "    inputs=[gene_input, type_input, review_input, assembly_input],\n",
        "    outputs=output\n",
        ")\n",
        "\n",
        "print(\"Model rebuilt successfully!\")\n"
      ],
      "metadata": {
        "id": "MfiEnLLwH7oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n",
        "\n",
        "model.load_weights(f\"{BASE_PATH}/transssv_style_model.keras\")\n",
        "print(\"Weights loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "R7TlEuakIFOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a SMALL subset just for demo\n",
        "X_demo = X_train.sample(50000, random_state=42)\n",
        "y_demo = y_train.loc[X_demo.index]\n",
        "\n",
        "history = model.fit(\n",
        "    {\n",
        "        \"gene_input\": X_demo.iloc[:,0],\n",
        "        \"type_input\": X_demo.iloc[:,1],\n",
        "        \"review_input\": X_demo.iloc[:,2],\n",
        "        \"assembly_input\": X_demo.iloc[:,3],\n",
        "    },\n",
        "    y_demo,\n",
        "    epochs=3,\n",
        "    batch_size=256\n",
        ")\n"
      ],
      "metadata": {
        "id": "-GKfdzeQIdZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7148619e-c00d-441d-f747-fedde4dcbf0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4074907435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use a SMALL subset just for demo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_demo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_demo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n",
        "\n",
        "X_train = pd.read_csv(f\"{BASE_PATH}/X_train.csv\")\n",
        "y_train = pd.read_csv(f\"{BASE_PATH}/y_train.csv\")\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n"
      ],
      "metadata": {
        "id": "kdplPQRpI-em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Small subset ONLY for demo\n",
        "X_demo = X_train.sample(n=50000, random_state=42)\n",
        "y_demo = y_train[X_demo.index]\n"
      ],
      "metadata": {
        "id": "Vrq2XtczJFn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_train to 1D Series\n",
        "if isinstance(y_train, pd.DataFrame):\n",
        "    y_train = y_train.iloc[:, 0]\n"
      ],
      "metadata": {
        "id": "sWC8RUc0JYG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_demo = X_train.sample(n=50000, random_state=42)\n",
        "y_demo = y_train.loc[X_demo.index]\n"
      ],
      "metadata": {
        "id": "OzhDfkDVJZ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_demo, y_demo = X_train.sample(\n",
        "    n=50000,\n",
        "    random_state=42\n",
        "), y_train.sample(\n",
        "    n=50000,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "W8yu8xZDJenm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    {\n",
        "        \"gene_input\": X_demo.iloc[:, 0].values,\n",
        "        \"type_input\": X_demo.iloc[:, 1].values,\n",
        "        \"review_input\": X_demo.iloc[:, 2].values,\n",
        "        \"assembly_input\": X_demo.iloc[:, 3].values,\n",
        "    },\n",
        "    y_demo.values,\n",
        "    epochs=3,\n",
        "    batch_size=256,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "yrot6YT-Jjk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Model compiled successfully!\")\n"
      ],
      "metadata": {
        "id": "WLhyMbNEJ9Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    {\n",
        "        \"gene_input\": X_demo.iloc[:, 0].values,\n",
        "        \"type_input\": X_demo.iloc[:, 1].values,\n",
        "        \"review_input\": X_demo.iloc[:, 2].values,\n",
        "        \"assembly_input\": X_demo.iloc[:, 3].values,\n",
        "    },\n",
        "    y_demo.values,\n",
        "    epochs=3,\n",
        "    batch_size=256,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "T_WE0NGdKB3r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "000b1c78-0071-4737-e4ff-e959cc40600c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4252535546.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m\"gene_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"type_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"review_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result, conf = predict_variant(\n",
        "    gene=\"HFE\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "print(\"Prediction:\", result)\n",
        "print(\"Confidence:\", conf)\n"
      ],
      "metadata": {
        "id": "mCrokr97KQFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_variant(...)\n",
        "# or\n",
        "predict_variant_with_probs(...)\n"
      ],
      "metadata": {
        "id": "cHNHbcuPNdNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BRCA2\n",
        "predict_variant(\n",
        "    gene=\"BRCA2\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "# TP53\n",
        "predict_variant(\n",
        "    gene=\"TP53\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "# MLH1\n",
        "predict_variant(\n",
        "    gene=\"MLH1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh37\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "hQgzlKjzNtVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ACTB\n",
        "predict_variant(\n",
        "    gene=\"ACTB\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh37\"\n",
        ")\n",
        "\n",
        "# GAPDH\n",
        "predict_variant(\n",
        "    gene=\"GAPDH\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "# RPLP0\n",
        "predict_variant(\n",
        "    gene=\"RPLP0\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh37\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "XlzxryOeN-Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deletion\n",
        "predict_variant(\n",
        "    gene=\"AP5Z1\",\n",
        "    variant_type=\"Deletion\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh37\"\n",
        ")\n",
        "\n",
        "# Duplication\n",
        "predict_variant(\n",
        "    gene=\"DMD\",\n",
        "    variant_type=\"Duplication\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "yTdvVpHpOGGj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f8b6d948-7f91-4e50-8185-cddfc644534c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predict_variant' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3604035012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Deletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m predict_variant(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AP5Z1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvariant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Deletion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreview_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"no assertion criteria provided\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_variant' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_variant(\n",
        "    gene=\"ZNF592\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "eAHzZZBVOLUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_variant_with_probs(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "LV3tditoOQYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_and_plot(\n",
        "    gene, variant_type, review_status, assembly\n",
        "):\n",
        "    def safe_encode(le, value):\n",
        "        return le.transform([value])[0] if value in le.classes_ else 0\n",
        "\n",
        "    input_data = {\n",
        "        \"gene_input\": np.array([safe_encode(gene_le, gene)]),\n",
        "        \"type_input\": np.array([safe_encode(type_le, variant_type)]),\n",
        "        \"review_input\": np.array([safe_encode(review_le, review_status)]),\n",
        "        \"assembly_input\": np.array([safe_encode(assembly_le, assembly)])\n",
        "    }\n",
        "\n",
        "    probs = model.predict(input_data, verbose=0)[0]\n",
        "\n",
        "    labels = [\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "\n",
        "    # ---- Plot ----\n",
        "    plt.figure()\n",
        "    plt.bar(labels, probs)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(\"Clinical Significance Prediction\")\n",
        "\n",
        "    for i, v in enumerate(probs):\n",
        "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    pred_label = labels[int(np.argmax(probs))]\n",
        "    return pred_label, probs\n"
      ],
      "metadata": {
        "id": "nfvUH_K-OnjU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label, probs = predict_and_plot(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n",
        "\n",
        "print(\"Predicted class:\", label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "14F8qiPNOuKU",
        "outputId": "a085d70f-35ed-4c0f-a6ee-3f3dc576c00d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gene_le' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1894562651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m label, probs = predict_and_plot(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mgene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BRCA1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvariant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"single nucleotide variant\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreview_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"criteria provided, multiple submitters, no conflicts\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0massembly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRCh38\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3848228925.py\u001b[0m in \u001b[0;36mpredict_and_plot\u001b[0;34m(gene, variant_type, review_status, assembly)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     input_data = {\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m\"gene_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msafe_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_le\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"type_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msafe_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_le\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m\"review_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msafe_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_le\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gene_le' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_plot(\n",
        "    gene=\"TP53\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "3Ln0_AJrPCze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_plot(\n",
        "    gene=\"ZNF592\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "hWr609q8PGE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFl7yItrPO-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, conf = predict_variant(\n",
        "    gene=\"ACTB\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh37\"\n",
        ")\n",
        "\n",
        "print(result, conf)\n"
      ],
      "metadata": {
        "id": "nocmZIcIMsiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, conf = predict_variant(\n",
        "    gene=\"ACTB\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"no assertion criteria provided\",\n",
        "    assembly=\"GRCh37\"\n",
        ")\n",
        "\n",
        "print(result, conf)\n"
      ],
      "metadata": {
        "id": "VX-rohjsNFY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_variant_with_probs(gene, variant_type, review_status, assembly):\n",
        "    def safe_encode(le, value):\n",
        "        return le.transform([value])[0] if value in le.classes_ else 0\n",
        "\n",
        "    input_data = {\n",
        "        \"gene_input\": np.array([safe_encode(gene_le, gene)]),\n",
        "        \"type_input\": np.array([safe_encode(type_le, variant_type)]),\n",
        "        \"review_input\": np.array([safe_encode(review_le, review_status)]),\n",
        "        \"assembly_input\": np.array([safe_encode(assembly_le, assembly)])\n",
        "    }\n",
        "\n",
        "    probs = model.predict(input_data, verbose=0)[0]\n",
        "\n",
        "    return {\n",
        "        \"BENIGN\": round(float(probs[0]), 3),\n",
        "        \"VUS\": round(float(probs[1]), 3),\n",
        "        \"PATHOGENIC\": round(float(probs[2]), 3)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "TyZRM-v8NHp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_variant_with_probs(\n",
        "    gene=\"BRCA1\",\n",
        "    variant_type=\"single nucleotide variant\",\n",
        "    review_status=\"criteria provided, multiple submitters, no conflicts\",\n",
        "    assembly=\"GRCh38\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "U45AEPpdNT2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "364H2zNZqpxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "RPG7972Yqznd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "zsHyM16fqh3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh\n"
      ],
      "metadata": {
        "id": "2mJFWsgDrK8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e9b85a-457e-41f1-d0b6-aa0ba6a4ddca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8.0K\n",
            "drwx------ 5 root root 4.0K Feb  3 17:27 drive\n",
            "drwxr-xr-x 1 root root 4.0K Dec  9 14:42 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "PqzqDbsHrlbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b18f72-4f44-42a6-c53c-8c1e50afd2d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'variant_summary.txt.gz': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "aakpP3trrnP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32da39d9-1a07-4f2e-be8b-fbc8df6e74a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc3e9a81"
      },
      "source": [
        "This code attempts to load your gzipped text file into a pandas DataFrame, assuming it's a tab-separated file. If the file uses a different delimiter (like commas), you'll need to modify `sep='\\t'` to `sep=','` or another appropriate delimiter.\n",
        "\n",
        "Once loaded, you can perform various operations like filtering, analysis, or visualization on this DataFrame for your project.\n",
        "\n",
        "Let me know if this is what you were expecting or if you need help with further analysis!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEsvWel_rzU2",
        "outputId": "7b3dd1c7-db13-44f2-cd2d-3f26c4008804"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-03 17:28:04--  https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz\n",
            "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.31, 130.14.250.7, 130.14.250.10, ...\n",
            "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 422086052 (403M) [application/x-gzip]\n",
            "Saving to: ‚Äòvariant_summary.txt.gz‚Äô\n",
            "\n",
            "variant_summary.txt 100%[===================>] 402.53M  41.1MB/s    in 10s     \n",
            "\n",
            "2026-02-03 17:28:14 (39.9 MB/s) - ‚Äòvariant_summary.txt.gz‚Äô saved [422086052/422086052]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "1-2qAtZesI-Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "_bG6Xg9usOut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71296bb1-f354-4ee3-841a-8eca287e9112"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'variant_summary.txt.gz': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv variant_summary.txt.gz.1 variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "j5oZxZy_svgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fa935c-7db8-4a56-a1d1-8dd6bfb02ebe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'variant_summary.txt.gz.1': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE4BBXILs1p8",
        "outputId": "495436fd-33eb-4670-f8f4-9c64bfad8c16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.6G\n",
            "drwx------ 5 root root 4.0K Feb  3 17:27 drive\n",
            "drwxr-xr-x 1 root root 4.0K Dec  9 14:42 sample_data\n",
            "-rw-r--r-- 1 root root 3.6G Feb  1 22:42 variant_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# ClinVar Variant Preprocessing Script\n",
        "# Purpose: Clean and preprocess variant_summary.txt.gz for ML/DL analysis\n",
        "# Author: janjas\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------ Step 1: Load Data -----------------------\n",
        "file_path = \"variant_summary.txt.gz\"  # path to your ClinVar file\n",
        "\n",
        "print(\"Loading gzipped file, this may take a few minutes...\")\n",
        "df = pd.read_csv(file_path, compression='gzip', sep='\\t', low_memory=False)\n",
        "\n",
        "print(f\"Original data shape: {df.shape}\")\n",
        "print(\"Columns available:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# ------------------ Step 2: Select Relevant Columns ------------------\n",
        "# Keep only columns necessary for variant impact analysis\n",
        "columns_to_keep = [\n",
        "    'VariationID',         # Unique variant ID\n",
        "    'GeneSymbol',          # Gene name\n",
        "    'ClinicalSignificance',# Pathogenicity info\n",
        "    'ReviewStatus',        # Review/curation status\n",
        "    'Type',                # Variant type (SNV, deletion, insertion, etc.)\n",
        "    'Assembly'             # Genome assembly (GRCh38/GRCh37)\n",
        "]\n",
        "\n",
        "df = df[columns_to_keep]\n",
        "print(f\"Data shape after column selection: {df.shape}\")\n",
        "\n",
        "# ------------------ Step 3: Handle Missing Data ------------------\n",
        "# Drop rows where essential info is missing\n",
        "df = df.dropna(subset=['GeneSymbol', 'ClinicalSignificance'])\n",
        "print(f\"Data shape after dropping missing values: {df.shape}\")\n",
        "\n",
        "# ------------------ Step 4: Remove Duplicates ------------------\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Data shape after removing duplicates: {df.shape}\")\n",
        "\n",
        "# ------------------ Step 5: Standardize Clinical Significance ------------------\n",
        "# Convert all to uppercase and remove leading/trailing spaces\n",
        "df['ClinicalSignificance'] = df['ClinicalSignificance'].str.upper().str.strip()\n",
        "\n",
        "# Optional: unify common clinical significance labels\n",
        "df['ClinicalSignificance'] = df['ClinicalSignificance'].replace({\n",
        "    'LIKELY PATHOGENIC': 'PATHOGENIC',\n",
        "    'UNCERTAIN SIGNIFICANCE': 'VUS',  # Variant of uncertain significance\n",
        "    'LIKELY BENIGN': 'BENIGN'\n",
        "})\n",
        "\n",
        "# ------------------ Step 6: Optional Filtering ------------------\n",
        "# Keep only variants of interest (e.g., pathogenic)\n",
        "# Comment out this line if you want all variants\n",
        "df_filtered = df[df['ClinicalSignificance'].isin(['PATHOGENIC', 'VUS', 'BENIGN'])]\n",
        "print(f\"Data shape after filtering clinical significance: {df_filtered.shape}\")\n",
        "\n",
        "# ------------------ Step 7: Save Cleaned Data ------------------\n",
        "output_file = \"variant_summary_cleaned.csv\"\n",
        "df_filtered.to_csv(output_file, index=False)\n",
        "print(f\"Cleaned data saved to {output_file}\")\n",
        "\n",
        "# ------------------ Step 8: Quick Summary ------------------\n",
        "print(\"Summary of Clinical Significance counts:\")\n",
        "print(df_filtered['ClinicalSignificance'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Qk3CmRGgtUb3",
        "outputId": "d0daeba0-0e6a-4f5b-a599-ccc6fab886ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading gzipped file, this may take a few minutes...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'variant_summary.txt.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2191446638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading gzipped file, this may take a few minutes...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original data shape: {df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;31m# error: Incompatible types in assignment (expression has type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0;31m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 handle = gzip.GzipFile(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    766\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'variant_summary.txt.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"variant_summary.txt.gz\"\n",
        "output_file = \"variant_summary_cleaned1.csv\"\n",
        "\n",
        "# Define the columns to keep\n",
        "columns_to_keep = [\n",
        "    'VariationID', 'GeneSymbol', 'ClinicalSignificance',\n",
        "    'ReviewStatus', 'Type', 'Assembly'\n",
        "]\n",
        "\n",
        "# Initialize CSV for writing cleaned data\n",
        "header_written = False\n",
        "\n",
        "# Process file in chunks\n",
        "chunk_size = 500000  # number of rows per chunk (adjust if needed)\n",
        "for chunk in pd.read_csv(file_path, compression='gzip', sep='\\t', usecols=columns_to_keep, chunksize=chunk_size):\n",
        "\n",
        "    # Drop rows with missing essential info\n",
        "    chunk = chunk.dropna(subset=['GeneSymbol', 'ClinicalSignificance'])\n",
        "\n",
        "    # Remove duplicates in this chunk\n",
        "    chunk = chunk.drop_duplicates()\n",
        "\n",
        "    # Standardize clinical significance\n",
        "    chunk['ClinicalSignificance'] = chunk['ClinicalSignificance'].str.upper().str.strip()\n",
        "    chunk['ClinicalSignificance'] = chunk['ClinicalSignificance'].replace({\n",
        "        'LIKELY PATHOGENIC': 'PATHOGENIC',\n",
        "        'UNCERTAIN SIGNIFICANCE': 'VUS',\n",
        "        'LIKELY BENIGN': 'BENIGN'\n",
        "    })\n",
        "\n",
        "    # Optional filtering: keep only PATHOGENIC, VUS, BENIGN\n",
        "    chunk = chunk[chunk['ClinicalSignificance'].isin(['PATHOGENIC', 'VUS', 'BENIGN'])]\n",
        "\n",
        "    # Append cleaned chunk to CSV\n",
        "    chunk.to_csv(output_file, mode='a', index=False, header=not header_written)\n",
        "    header_written = True\n",
        "\n",
        "print(f\"Memory-efficient preprocessing done. Cleaned data saved to {output_file}\")\n"
      ],
      "metadata": {
        "id": "8Z7old8aubH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"variant_summary_cleaned1.csv\")\n",
        "print(df.shape)\n",
        "print(df['ClinicalSignificance'].value_counts())\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "8cBv__g-vA8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# ClinVar Preprocessing for Deep Learning\n",
        "# Author: janjas\n",
        "# Purpose: Encode categorical features, target, and split train/test\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------------ Step 1: Load Cleaned Data ------------------\n",
        "df = pd.read_csv(\"variant_summary_cleaned1.csv\")\n",
        "print(f\"Loaded data shape: {df.shape}\")\n",
        "\n",
        "# ------------------ Step 2: Encode Target ---------------------\n",
        "# Map ClinicalSignificance to integers\n",
        "target_mapping = {'BENIGN': 0, 'VUS': 1, 'PATHOGENIC': 2}\n",
        "df['ClinicalSignificance_encoded'] = df['ClinicalSignificance'].map(target_mapping)\n",
        "\n",
        "# ------------------ Step 3: Encode Categorical Features -------\n",
        "# High-cardinality feature: GeneSymbol\n",
        "gene_le = LabelEncoder()\n",
        "df['GeneSymbol_encoded'] = gene_le.fit_transform(df['GeneSymbol'])\n",
        "\n",
        "# Smaller categorical features\n",
        "small_categorical = ['Type', 'ReviewStatus', 'Assembly']\n",
        "for col in small_categorical:\n",
        "    le = LabelEncoder()\n",
        "    df[col + \"_encoded\"] = le.fit_transform(df[col])\n",
        "\n",
        "# ------------------ Step 4: Prepare Features and Target -------\n",
        "feature_cols = ['GeneSymbol_encoded', 'Type_encoded', 'ReviewStatus_encoded', 'Assembly_encoded']\n",
        "X = df[feature_cols]\n",
        "y = df['ClinicalSignificance_encoded']\n",
        "\n",
        "print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
        "\n",
        "# ------------------ Step 5: Train/Test Split ------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
        "\n",
        "# ------------------ Step 6: Save Preprocessed Data -------------\n",
        "X_train.to_csv(\"X_train.csv\", index=False)\n",
        "X_test.to_csv(\"X_test.csv\", index=False)\n",
        "y_train.to_csv(\"y_train.csv\", index=False)\n",
        "y_test.to_csv(\"y_test.csv\", index=False)\n",
        "\n",
        "print(\"Preprocessing complete. Train/test datasets saved!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CN6yqJ2fvq4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Get the number of unique categories for each feature from the LabelEncoders used previously\n",
        "# The LabelEncoders are defined in the previous cell (CN6yqJ2fvq4Y).\n",
        "num_genes = len(gene_le.classes_)\n",
        "num_types = len(le.classes_) if 'Type_encoded' in df.columns else len(df['Type'].unique()) # assuming 'le' is the last used for small_categorical\n",
        "num_reviews = len(le.classes_) if 'ReviewStatus_encoded' in df.columns else len(df['ReviewStatus'].unique())\n",
        "num_assembly = len(le.classes_) if 'Assembly_encoded' in df.columns else len(df['Assembly'].unique())\n",
        "\n",
        "# Define input shapes\n",
        "gene_input = Input(shape=(1,), name=\"gene_input\")\n",
        "type_input = Input(shape=(1,), name=\"type_input\")\n",
        "review_input = Input(shape=(1,), name=\"review_input\")\n",
        "assembly_input = Input(shape=(1,), name=\"assembly_input\")\n",
        "\n",
        "# Embeddings\n",
        "gene_emb = Embedding(input_dim=num_genes, output_dim=64)(gene_input)\n",
        "type_emb = Embedding(input_dim=num_types, output_dim=8)(type_input)\n",
        "review_emb = Embedding(input_dim=num_reviews, output_dim=16)(review_input)\n",
        "assembly_emb = Embedding(input_dim=num_assembly, output_dim=4)(assembly_input)\n",
        "\n",
        "# Flatten embedding outputs\n",
        "gene_emb_flat = tf.keras.layers.Flatten()(gene_emb)\n",
        "type_emb_flat = tf.keras.layers.Flatten()(type_emb)\n",
        "review_emb_flat = tf.keras.layers.Flatten()(review_emb)\n",
        "assembly_emb_flat = tf.keras.layers.Flatten()(assembly_emb)\n",
        "\n",
        "# Concatenate all features\n",
        "x = Concatenate()([\n",
        "    gene_emb_flat,\n",
        "    type_emb_flat,\n",
        "    review_emb_flat,\n",
        "    assembly_emb_flat\n",
        "])\n",
        "\n",
        "# Optional Transformer-style block (self-attention)\n",
        "# Project to higher dim\n",
        "x_proj = Dense(256, activation=\"relu\")(x)\n",
        "# Self-attention\n",
        "attn_output = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)(x_proj[:, None, :], x_proj[:, None, :])\n",
        "# Flatten back\n",
        "attn_flat = tf.keras.layers.Flatten()(attn_output)\n",
        "\n",
        "# Combine and normalize\n",
        "x_combined = Concatenate()([x, attn_flat])\n",
        "x_norm = LayerNormalization()(x_combined)\n",
        "\n",
        "# Dense layers\n",
        "x_dense = Dense(128, activation=\"relu\")(x_norm)\n",
        "x_drop = Dropout(0.3)(x_dense)\n",
        "x_dense2 = Dense(64, activation=\"relu\")(x_drop)\n",
        "\n",
        "# Output: 3 classes (benign, VUS, pathogenic)\n",
        "output = Dense(3, activation=\"softmax\")(x_dense2)\n",
        "\n",
        "# Build and compile\n",
        "model = Model(\n",
        "    inputs=[gene_input, type_input, review_input, assembly_input],\n",
        "    outputs=output\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CoSVDrBUwQ4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ------------------ Load Train/Test Data ------------------\n",
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")\n",
        "\n",
        "# ------------------ Define Input Sizes --------------------\n",
        "# Use the full dataset's unique counts to define embedding dimensions\n",
        "# This ensures all possible encoded values (from both train and test sets) are covered\n",
        "# df is available in the kernel state from a previous cell where it was loaded (variant_summary_cleaned.csv).\n",
        "num_genes = df['GeneSymbol_encoded'].max() + 1\n",
        "num_types = df['Type_encoded'].max() + 1\n",
        "num_reviews = df['ReviewStatus_encoded'].max() + 1\n",
        "num_assembly = df['Assembly_encoded'].max() + 1\n",
        "\n",
        "# ------------------ Build Transformer-style Model ---------\n",
        "gene_input = Input(shape=(1,), name=\"gene_input\")\n",
        "type_input = Input(shape=(1,), name=\"type_input\")\n",
        "review_input = Input(shape=(1,), name=\"review_input\")\n",
        "assembly_input = Input(shape=(1,), name=\"assembly_input\")\n",
        "\n",
        "gene_emb = Embedding(input_dim=num_genes, output_dim=64)(gene_input)\n",
        "type_emb = Embedding(input_dim=num_types, output_dim=8)(type_input)\n",
        "review_emb = Embedding(input_dim=num_reviews, output_dim=16)(review_input)\n",
        "assembly_emb = Embedding(input_dim=num_assembly, output_dim=4)(assembly_input)\n",
        "\n",
        "gene_flat = tf.keras.layers.Flatten()(gene_emb)\n",
        "type_flat = tf.keras.layers.Flatten()(type_emb)\n",
        "review_flat = tf.keras.layers.Flatten()(review_emb)\n",
        "assembly_flat = tf.keras.layers.Flatten()(assembly_emb)\n",
        "\n",
        "x = Concatenate()([gene_flat, type_flat, review_flat, assembly_flat])\n",
        "\n",
        "# Transformer-style attention block (corrected to use Lambda layers)\n",
        "x_proj = Dense(256, activation='relu')(x)\n",
        "\n",
        "# Expand dims to simulate sequence length = 1 for MultiHeadAttention\n",
        "x_seq = tf.keras.layers.Lambda(lambda t: tf.expand_dims(t, axis=1), name=\"expand_dims_for_mha\")(x_proj)\n",
        "\n",
        "# Apply MultiHeadAttention\n",
        "attn_output = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64)(x_seq, x_seq)\n",
        "\n",
        "# Remove sequence dimension\n",
        "attn_output = tf.keras.layers.Lambda(lambda t: tf.squeeze(t, axis=1), name=\"squeeze_after_mha\")(attn_output)\n",
        "\n",
        "# Residual connection + Layer Normalization\n",
        "x_norm = LayerNormalization()(x_proj + attn_output)\n",
        "\n",
        "# Dense layers after attention\n",
        "x_dense = Dense(128, activation='relu')(x_norm)\n",
        "x_drop = Dropout(0.3)(x_dense)\n",
        "x_dense2 = Dense(64, activation='relu')(x_drop)\n",
        "output = Dense(3, activation='softmax')(x_dense2)\n",
        "\n",
        "model = Model(inputs=[gene_input, type_input, review_input, assembly_input], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ------------------ Prepare Inputs ------------------------\n",
        "train_inputs = {\n",
        "    \"gene_input\": X_train['GeneSymbol_encoded'].values,\n",
        "    \"type_input\": X_train['Type_encoded'].values,\n",
        "    \"review_input\": X_train['ReviewStatus_encoded'].values,\n",
        "    \"assembly_input\": X_train['Assembly_encoded'].values\n",
        "}\n",
        "\n",
        "test_inputs = {\n",
        "    \"gene_input\": X_test['GeneSymbol_encoded'].values,\n",
        "    \"type_input\": X_test['Type_encoded'].values,\n",
        "    \"review_input\": X_test['ReviewStatus_encoded'].values,\n",
        "    \"assembly_input\": X_test['Assembly_encoded'].values\n",
        "}\n",
        "\n",
        "# ------------------ Train Model ---------------------------\n",
        "history = model.fit(\n",
        "    train_inputs,\n",
        "    y_train.values,\n",
        "    validation_split=0.1,\n",
        "    epochs=15,          # start small; increase after testing\n",
        "    batch_size=512\n",
        ")"
      ],
      "metadata": {
        "id": "cBgFk8qxxkCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_probs = model.predict(test_inputs, batch_size=256)\n",
        "y_pred = y_pred_probs.argmax(axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    target_names=[\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "kTqP3EX5twcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"baseline_dl_model.h5\")\n"
      ],
      "metadata": {
        "id": "sFvEjm7uuIT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"baseline_dl_model.keras\")\n"
      ],
      "metadata": {
        "id": "bhOA7sB3uIYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"baseline_dl_model.keras\")\n"
      ],
      "metadata": {
        "id": "lZ4TkNQGuj2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention\n",
        "\n",
        "# Fix: Define the 'mha' object using parameters from the previous model definition.\n",
        "mha = MultiHeadAttention(num_heads=4, key_dim=64)\n",
        "\n",
        "attn_out = mha(x, x)\n",
        "x = LayerNormalization()(x + attn_out)\n"
      ],
      "metadata": {
        "id": "P2CfSfQZvHf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense\n"
      ],
      "metadata": {
        "id": "2_e2AdYSvXxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Dense, Concatenate, Dropout,\n",
        "    LayerNormalization, Flatten, MultiHeadAttention\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------ Load SMALL DATA ------------------\n",
        "X_train = pd.read_csv(\"X_train_small.csv\")\n",
        "y_train = pd.read_csv(\"y_train_small.csv\")\n",
        "X_test  = pd.read_csv(\"X_test_small.csv\")\n",
        "y_test  = pd.read_csv(\"y_test_small.csv\")\n",
        "\n",
        "# ------------------ Vocabulary sizes -----------------\n",
        "num_genes    = X_train['GeneSymbol_encoded'].nunique()\n",
        "num_types    = X_train['Type_encoded'].nunique()\n",
        "num_reviews  = X_train['ReviewStatus_encoded'].nunique()\n",
        "num_assembly = X_train['Assembly_encoded'].nunique()\n",
        "\n",
        "# ------------------ Inputs ---------------------------\n",
        "gene_input     = Input(shape=(1,), name=\"gene_input\")\n",
        "type_input     = Input(shape=(1,), name=\"type_input\")\n",
        "review_input   = Input(shape=(1,), name=\"review_input\")\n",
        "assembly_input = Input(shape=(1,), name=\"assembly_input\")\n",
        "\n",
        "# ------------------ Embeddings -----------------------\n",
        "gene_emb     = Embedding(num_genes, 64)(gene_input)\n",
        "type_emb     = Embedding(num_types, 8)(type_input)\n",
        "review_emb   = Embedding(num_reviews, 16)(review_input)\n",
        "assembly_emb = Embedding(num_assembly, 4)(assembly_input)\n",
        "\n",
        "gene_flat     = Flatten()(gene_emb)\n",
        "type_flat     = Flatten()(type_emb)\n",
        "review_flat   = Flatten()(review_emb)\n",
        "assembly_flat = Flatten()(assembly_emb)\n",
        "\n",
        "# ------------------ Concatenate ----------------------\n",
        "x = Concatenate()([gene_flat, type_flat, review_flat, assembly_flat])\n",
        "\n",
        "# ------------------ Projection -----------------------\n",
        "x_proj = Dense(256, activation=\"relu\")(x)\n",
        "\n",
        "# ------------------ Transformer Attention Block ------\n",
        "# Define MHA\n",
        "mha = MultiHeadAttention(num_heads=4, key_dim=64)\n",
        "\n",
        "# Expand dims to (batch, seq_len=1, features)\n",
        "x_seq = tf.expand_dims(x_proj, axis=1)\n",
        "\n",
        "# Self-attention\n",
        "attn_out = mha(x_seq, x_seq)\n",
        "\n",
        "# Remove seq dimension\n",
        "attn_out = tf.squeeze(attn_out, axis=1)\n",
        "\n",
        "# Residual + LayerNorm\n",
        "x_attn = LayerNormalization()(x_proj + attn_out)\n",
        "\n",
        "# ------------------ Feed Forward Network -------------\n",
        "ffn = Dense(256, activation=\"relu\")(x_attn)\n",
        "x_attn = LayerNormalization()(x_attn + ffn)\n",
        "\n",
        "# ------------------ Classifier -----------------------\n",
        "x = Dense(128, activation=\"relu\")(x_attn)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "output = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "# ------------------ Build Model ----------------------\n",
        "model = Model(\n",
        "    inputs=[gene_input, type_input, review_input, assembly_input],\n",
        "    outputs=output\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "9giXt3_-w_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention(\n",
        "    num_heads=4,\n",
        "    key_dim=64,\n",
        "    name=\"self_attention\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "2DEvZDNPxfTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand dims to simulate sequence length = 1\n",
        "x_seq = tf.expand_dims(x_proj, axis=1)  # (None, 1, 256)\n",
        "\n",
        "# Self-attention\n",
        "attn_out = mha(x_seq, x_seq)             # (None, 1, 256)\n",
        "\n",
        "# Remove sequence dimension\n",
        "attn_out = tf.squeeze(attn_out, axis=1) # (None, 256)\n",
        "\n",
        "# Residual connection + normalization\n",
        "x_attn = LayerNormalization()(x_proj + attn_out)\n"
      ],
      "metadata": {
        "id": "pqiiha0_xhJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "# ------------------ Transformer Attention Block ------\n",
        "\n",
        "# Projected feature vector: (None, 256)\n",
        "\n",
        "# Step 1: Convert vector ‚Üí sequence (seq_len = 1)\n",
        "x_seq = Reshape((1, 256))(x_proj)   # ‚úÖ Keras-safe\n",
        "\n",
        "# Step 2: Define attention\n",
        "mha = MultiHeadAttention(\n",
        "    num_heads=4,\n",
        "    key_dim=64\n",
        ")\n",
        "\n",
        "# Step 3: Self-attention\n",
        "attn_out = mha(x_seq, x_seq)        # (None, 1, 256)\n",
        "\n",
        "# Step 4: Back to vector\n",
        "attn_out = Reshape((256,))(attn_out)\n",
        "\n",
        "# Step 5: Residual + LayerNorm\n",
        "x_attn = LayerNormalization()(x_proj + attn_out)\n",
        "\n",
        "# Step 6: Feed-forward block\n",
        "ffn = Dense(256, activation=\"relu\")(x_attn)\n",
        "x_attn = LayerNormalization()(x_attn + ffn)\n"
      ],
      "metadata": {
        "id": "L64lQhtlxyUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(test_inputs, batch_size=512)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\n",
        "    \"BENIGN\", \"VUS\", \"PATHOGENIC\"\n",
        "]))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "UwCbQpt8yBz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"transssv_style_model.keras\")\n"
      ],
      "metadata": {
        "id": "cBUaeWrcyLtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 2‚Äì3 more epochs safely\n",
        "history_extra = model.fit(\n",
        "    train_inputs,\n",
        "    y_train,\n",
        "    validation_data=(val_inputs, y_val),\n",
        "    epochs=3,              # ONLY 3\n",
        "    batch_size=512,        # keep it stable\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Oxj-s4fDyd5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_extra = model.fit(\n",
        "    train_inputs,\n",
        "    y_train,\n",
        "    epochs=3,          # only 3 more\n",
        "    batch_size=512,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "VOrLgGUhyqsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/UG_Project/transssv_final.keras\")\n"
      ],
      "metadata": {
        "id": "spqvJRodUCsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(test_inputs, batch_size=512)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(\"Final Classification Report:\")\n",
        "print(classification_report(\n",
        "    y_test, y_pred,\n",
        "    target_names=[\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "))\n",
        "\n",
        "print(\"Final Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "7ivwwX34zTYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"transssv_final.keras\")\n"
      ],
      "metadata": {
        "id": "mlQwqadCy8Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = [\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(cm)\n",
        "plt.xticks(range(3), labels)\n",
        "plt.yticks(range(3), labels)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1l74w0S-y-r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_counts = pd.Series(y_train).value_counts()\n",
        "\n",
        "plt.figure()\n",
        "class_counts.plot(kind=\"bar\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution in Training Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qdsEafTz0RJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Flatten y_train\n",
        "y_train_flat = y_train.reshape(-1)\n",
        "\n",
        "class_counts = pd.Series(y_train_flat).value_counts()\n",
        "\n",
        "plt.figure()\n",
        "class_counts.plot(kind=\"bar\")\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution in Training Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t4vSRutb1BHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Flatten y_train\n",
        "y_train_flat = y_train.to_numpy().ravel()  # <-- fixed\n",
        "\n",
        "# Count classes\n",
        "class_counts = pd.Series(y_train_flat).value_counts()\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "class_counts.plot(kind=\"bar\")\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution in Training Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qBG8qftF1QvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts.index = [\"BENIGN\", \"VUS\", \"PATHOGENIC\"]\n"
      ],
      "metadata": {
        "id": "Gee-YqgF1bTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.savefig(\"class_distribution.png\", dpi=300, bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "UrAPwfsT1hMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ClinVar data\n",
        "!wget https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "9GgBBdA472Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"encoders.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoders, f)\n"
      ],
      "metadata": {
        "id": "_EmWuCMNLS08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n",
        "\n",
        "# Load the same cleaned dataset used for training\n",
        "df = pd.read_csv(f\"{BASE_PATH}/variant_summary_cleaned1.csv\")\n",
        "\n",
        "encoders = {}\n",
        "\n",
        "for col in [\"GeneSymbol\", \"Type\", \"ReviewStatus\", \"Assembly\"]:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# Save encoders to the correct path\n",
        "with open(f\"{BASE_PATH}/encoders.pkl\", \"wb\") as f:\n",
        "    pickle.dump(encoders, f)\n",
        "\n",
        "print(\"Encoders generated and saved successfully!\")"
      ],
      "metadata": {
        "id": "omTQQJj6Lh1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "wMsVZNUMUWMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZIWuh5xJLnIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "jxG7ijevL7Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/UG_Project\n"
      ],
      "metadata": {
        "id": "NcKBzz28MFwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content/drive/MyDrive/UG_Project \\\n",
        "https://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz\n"
      ],
      "metadata": {
        "id": "EU8-vT5oMLX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "lkCqY1yqMX3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \\\n",
        "transssv_style_model.keras \\\n",
        "encoders.pkl \\\n",
        "variant_summary.txt.gz \\\n",
        "variant_summary_cleaned1.csv \\\n",
        "X_train.csv \\\n",
        "X_test.csv \\\n",
        "y_train.csv \\\n",
        "y_test.csv \\\n",
        "/content/drive/MyDrive/UG_Project/"
      ],
      "metadata": {
        "id": "Cf8jOj7VUs9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/UG_Project\n"
      ],
      "metadata": {
        "id": "uhreKQVGVCGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/UG_Project_base_comparison_model.zip /content/drive/MyDrive/UG_Project\n"
      ],
      "metadata": {
        "id": "VCox1zeAVWX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n"
      ],
      "metadata": {
        "id": "9FmYeFgUWA97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Lambda, MultiHeadAttention, LayerNormalization # Import necessary layers if they were custom or used in Lambda\n",
        "\n",
        "# Define the lambda functions explicitly as they were used in the model definition\n",
        "def expand_dims_func(t):\n",
        "    return tf.expand_dims(t, axis=1)\n",
        "\n",
        "def squeeze_func(t):\n",
        "    return tf.squeeze(t, axis=1)\n",
        "\n",
        "# Create a custom_objects dictionary to handle Lambda layers with specified output shapes\n",
        "# These output shapes are derived from the model's architecture in cell cBgFk8qxxkCt.\n",
        "custom_objects = {\n",
        "    'expand_dims_for_mha': Lambda(expand_dims_func, output_shape=(1, 256)),\n",
        "    'squeeze_after_mha': Lambda(squeeze_func, output_shape=(256,)),\n",
        "    # Include other custom layers if they were part of the saved model and not standard Keras layers\n",
        "    'MultiHeadAttention': MultiHeadAttention, # This is a standard layer, but sometimes needed in custom_objects\n",
        "    'LayerNormalization': LayerNormalization # Same for LayerNormalization\n",
        "}\n",
        "\n",
        "# Load trained model, including custom objects and safe_mode=False\n",
        "model = load_model(\n",
        "    f\"{BASE_PATH}/transssv_style_model.keras\",\n",
        "    custom_objects=custom_objects,\n",
        "    safe_mode=False\n",
        ")\n",
        "\n",
        "# Load encoders\n",
        "with open(f\"{BASE_PATH}/encoders.pkl\", \"rb\") as f:\n",
        "    encoders = pickle.load(f)\n",
        "\n",
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n",
        "\n",
        "print(\"Model and encoders loaded successfully!\")"
      ],
      "metadata": {
        "id": "hIAEPE8HWCa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Lambda\n"
      ],
      "metadata": {
        "id": "nJ3ZhdBqWR9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\n",
        "    f\"{BASE_PATH}/transssv_style_model.keras\",\n",
        "    custom_objects={\n",
        "        \"tf\": tf\n",
        "    },\n",
        "    compile=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "t6hbGldlWVI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.config.enable_unsafe_deserialization()\n"
      ],
      "metadata": {
        "id": "3mApxUiqWkq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\n",
        "    f\"{BASE_PATH}/transssv_style_model.keras\",\n",
        "    compile=False\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "HJ5QfEANWpXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Dense, Concatenate, Dropout,\n",
        "    LayerNormalization, Flatten, MultiHeadAttention, Reshape\n",
        ")\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "UNjutEaiW511"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary sizes (load from encoders)\n",
        "num_genes = len(gene_le.classes_)\n",
        "num_types = len(type_le.classes_)\n",
        "num_reviews = len(review_le.classes_)\n",
        "num_assembly = len(assembly_le.classes_)\n",
        "\n",
        "# Inputs\n",
        "gene_input = Input(shape=(1,), name=\"gene_input\")\n",
        "type_input = Input(shape=(1,), name=\"type_input\")\n",
        "review_input = Input(shape=(1,), name=\"review_input\")\n",
        "assembly_input = Input(shape=(1,), name=\"assembly_input\")\n",
        "\n",
        "# Embeddings\n",
        "gene_emb = Embedding(num_genes, 64)(gene_input)\n",
        "type_emb = Embedding(num_types, 8)(type_input)\n",
        "review_emb = Embedding(num_reviews, 16)(review_input)\n",
        "assembly_emb = Embedding(num_assembly, 4)(assembly_input)\n",
        "\n",
        "x = Concatenate()([\n",
        "    Flatten()(gene_emb),\n",
        "    Flatten()(type_emb),\n",
        "    Flatten()(review_emb),\n",
        "    Flatten()(assembly_emb)\n",
        "])\n",
        "\n",
        "# Projection\n",
        "x_proj = Dense(256, activation=\"relu\")(x)\n",
        "\n",
        "# Transformer attention (NO Lambda)\n",
        "x_seq = Reshape((1, 256))(x_proj)\n",
        "attn = MultiHeadAttention(num_heads=4, key_dim=64)(x_seq, x_seq)\n",
        "attn = Reshape((256,))(attn)\n",
        "\n",
        "x_attn = LayerNormalization()(x_proj + attn)\n",
        "\n",
        "# Feed-forward\n",
        "ffn = Dense(256, activation=\"relu\")(x_attn)\n",
        "x_attn = LayerNormalization()(x_attn + ffn)\n",
        "\n",
        "# Classifier\n",
        "x = Dense(128, activation=\"relu\")(x_attn)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "output = Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "# Model\n",
        "model = Model(\n",
        "    inputs=[gene_input, type_input, review_input, assembly_input],\n",
        "    outputs=output\n",
        ")\n"
      ],
      "metadata": {
        "id": "xHMPARuZW9-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/UG_Project\"\n",
        "\n",
        "with open(f\"{BASE_PATH}/encoders.pkl\", \"rb\") as f:\n",
        "    encoders = pickle.load(f)\n",
        "\n",
        "gene_le = encoders[\"GeneSymbol\"]\n",
        "type_le = encoders[\"Type\"]\n",
        "review_le = encoders[\"ReviewStatus\"]\n",
        "assembly_le = encoders[\"Assembly\"]\n",
        "\n",
        "print(\"Encoders loaded:\")\n",
        "print(len(gene_le.classes_), len(type_le.classes_),\n",
        "      len(review_le.classes_), len(assembly_le.classes_))\n"
      ],
      "metadata": {
        "id": "xAOPmkwnXL6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}